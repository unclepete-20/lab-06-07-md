{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo básico con TensorFlow 2.0\n",
    "\n",
    "En este ejercicio vamos a recrear nuestro algoritmo de aprendizaje utilizando TF 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar las librerías relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de datos\n",
    "\n",
    "Se generan los datos de la misma manera que lo hicimos en el ejercicio anterior.  La única diferencia es que ahora se guardan los datos en un archivo *.npz*.  NPZ es un tipo de archivo propio de NumPy que permite guardar arreglos NumPy.  Se introduce este cambio porque en el ML a menudo:\n",
    "\n",
    "* se reciben datos (csv, base de datos, etc.)\n",
    "* se preprocesan los datos y se dejan en un formato deseado (se verá este tema después)\n",
    "* se guardan los datos en archivos npz (si es que se está trabajando con Python) para uso posterior\n",
    "\n",
    "No hay nada especial de todo esto.  Solo se guardan arreglos NumPy en un archivo re-utlizable.\n",
    "\n",
    "Se trabajará con dos variables de entrada, x1 y x2.  Estas se generan al azar a partir de una distribución uniforme.\n",
    "\n",
    "Se creará una matriz con estas dos variables.  La matriz X del modelo lineal y = x * w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por facilidad, declaramos una variable que indique el tamaño del conjunto \n",
    "#      de datos de entrenamiento.\n",
    "observaciones = 1000\n",
    "\n",
    "x1 = np.random.uniform(low = -10, high = 10, size = (observaciones,1))\n",
    "x2 = np.random.uniform(-10, 10, (observaciones,1)) # nótese que no se requieren las palabras clave\n",
    "\n",
    "X = np.column_stack((x1,x2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar las metas a las que debemos apuntar\n",
    "\n",
    "La función a usar: \n",
    "\n",
    "f(x1, x2) = 2 * x1 - 3 * x2 + 5 + <ruido pequeño>\n",
    "\n",
    "El ruido es para hacerlo más realista.\n",
    "\n",
    "En esencia, se puede ver que los pesos serán 2 y -3, y es sesgo es 5\n",
    "\n",
    "Utilizando la metodología de ML, se vé si el algoritmo ha aprendido la función. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruido = np.random.uniform(-1, 1, (observaciones,1))\n",
    "\n",
    "y = 2 * x1 - 3 * x2 + 5 + ruido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora todo ha sido igual.  El siguiente paso sí es nuevo y es que se guarda la información en un archivo *.npz* que se ha denominado \"Datos_TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Datos_TF', entradas = X, targets = y)  # nótese que se puede usar cualquier nombre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolver con TensorFlow\n",
    "\n",
    "<i/>Nota: Esta introducción de TensorFloe es muy básica.  El TF tiene muchas más capacidaded y profundidad que esto.<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan los datos desde el archivo NPZ.  Por supuesto, esto no era necesario acá\n",
    "datos = np.load('Datos_TF.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejercicio anterior se tuvieron que dar valores iniciales, acá solo se dan:\n",
    "\n",
    "1.  El número de variables de entrada\n",
    "2.  El número de salidas que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanio_entrada = 2\n",
    "\n",
    "tamanio_salida = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describir el modelo\n",
    "\n",
    "En otras aplicaciones simplemente se usa un modelo que ya se haya hecho.  Con TensorFlow hay que armarlo\n",
    "\n",
    "Como el ejemplo es muy simple...es lineal...se utiliza el método **\"Sequential\"**\n",
    "\n",
    "Nótese que no se pide cálculo alguno - solo se describe la red\n",
    "\n",
    "Acá se debe listar cada capa \"layer\" de la red neuronal\n",
    "\n",
    "El método **\"Dense\"** realiza una operación matemática **.dot(u, v) + z**.  Esto es exactamente lo que que se necesita: (xw + b)\n",
    "\n",
    "El único parámetro necesario es el tamaño de la salida **tamanio_salida** en el código\n",
    "\n",
    "Hay otros parámetros que se pueden incluir para particularizar el modelo, en este caso, se está tratando de crear una solución que sea tan parecida a la del modelo NumPy anterior por lo que se agregan:\n",
    "\n",
    "* kernel_initializer   -   kernel es un término más generalizado para los pesos\n",
    "* bias_initializer     -   sesgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 09:22:15.691991: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "                           \n",
    "                            tf.keras.layers.Dense(tamanio_salida,\n",
    "                                                 kernel_initializer = tf.random_uniform_initializer(minval = -0.1, maxval = 0.1),\n",
    "                                                 bias_initializer = tf.random_uniform_initializer(minval = -0.1, maxval = 0.1)\n",
    "                                                 )\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se puede definir un optimizador a la medida, en el que se puede especificar la tasa de aprendizaje. De los que hay disponibles, el SGD (Stochastic Gradient Descent) es una generalización de la que se platicó en clase, sin darle nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizador_adhoc = tf.keras.optimizers.SGD(learning_rate = 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la función de pérdida, se utilizará la de **L2-norm**.  Esta también se conoce como **Least sum of squares (Least sum of squares error)**.  El escalamiento se logra obteniendo la media para el # de observaciones.  Esto es justamente lo que hace el **mean squared error**\n",
    "\n",
    "En algún momento, podría ser necesario una función de pérdida hecha a la medida.  Eso es mucho más difícil implementar y no se trabajará en este curso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"compile\"** es donde se pueden indicar los optimizadores y la pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(optimizer = optimizador_adhoc, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se ajusta el modelo con los datos (o se modelan los datos), indicando las *entradas* y los *targets*...así se denominaron al guardar el archivo.  \n",
    "\n",
    "En vez de usar el término *iteraciones*, se utiliza el término *épocas*.  Si no se especifica el número de épocas este será 1 (una sola época de entrenamiento), así que este número es algo obligatorio.\n",
    "\n",
    "El parámetro **\"verbose\"** se refiere a cuánta información queremos que despliegue durante la ejecución.  Se vale probar diferentes números...se prueban los valores 0, 1 y 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 - 0s - loss: 0.3977 - 16ms/epoch - 490us/step\n",
      "Epoch 2/100\n",
      "32/32 - 0s - loss: 0.3732 - 13ms/epoch - 394us/step\n",
      "Epoch 3/100\n",
      "32/32 - 0s - loss: 0.3675 - 10ms/epoch - 327us/step\n",
      "Epoch 4/100\n",
      "32/32 - 0s - loss: 0.4443 - 10ms/epoch - 300us/step\n",
      "Epoch 5/100\n",
      "32/32 - 0s - loss: 0.4192 - 10ms/epoch - 315us/step\n",
      "Epoch 6/100\n",
      "32/32 - 0s - loss: 0.3875 - 10ms/epoch - 309us/step\n",
      "Epoch 7/100\n",
      "32/32 - 0s - loss: 0.4038 - 10ms/epoch - 299us/step\n",
      "Epoch 8/100\n",
      "32/32 - 0s - loss: 0.4134 - 10ms/epoch - 305us/step\n",
      "Epoch 9/100\n",
      "32/32 - 0s - loss: 0.3906 - 10ms/epoch - 301us/step\n",
      "Epoch 10/100\n",
      "32/32 - 0s - loss: 0.3697 - 10ms/epoch - 308us/step\n",
      "Epoch 11/100\n",
      "32/32 - 0s - loss: 0.4036 - 10ms/epoch - 308us/step\n",
      "Epoch 12/100\n",
      "32/32 - 0s - loss: 0.3972 - 9ms/epoch - 294us/step\n",
      "Epoch 13/100\n",
      "32/32 - 0s - loss: 0.3795 - 10ms/epoch - 300us/step\n",
      "Epoch 14/100\n",
      "32/32 - 0s - loss: 0.4110 - 10ms/epoch - 313us/step\n",
      "Epoch 15/100\n",
      "32/32 - 0s - loss: 0.3906 - 10ms/epoch - 301us/step\n",
      "Epoch 16/100\n",
      "32/32 - 0s - loss: 0.3893 - 10ms/epoch - 316us/step\n",
      "Epoch 17/100\n",
      "32/32 - 0s - loss: 0.4066 - 10ms/epoch - 306us/step\n",
      "Epoch 18/100\n",
      "32/32 - 0s - loss: 0.3890 - 10ms/epoch - 309us/step\n",
      "Epoch 19/100\n",
      "32/32 - 0s - loss: 0.3784 - 10ms/epoch - 311us/step\n",
      "Epoch 20/100\n",
      "32/32 - 0s - loss: 0.3869 - 9ms/epoch - 296us/step\n",
      "Epoch 21/100\n",
      "32/32 - 0s - loss: 0.3791 - 10ms/epoch - 302us/step\n",
      "Epoch 22/100\n",
      "32/32 - 0s - loss: 0.3738 - 10ms/epoch - 308us/step\n",
      "Epoch 23/100\n",
      "32/32 - 0s - loss: 0.4395 - 10ms/epoch - 299us/step\n",
      "Epoch 24/100\n",
      "32/32 - 0s - loss: 0.4235 - 10ms/epoch - 325us/step\n",
      "Epoch 25/100\n",
      "32/32 - 0s - loss: 0.3928 - 10ms/epoch - 302us/step\n",
      "Epoch 26/100\n",
      "32/32 - 0s - loss: 0.4016 - 10ms/epoch - 302us/step\n",
      "Epoch 27/100\n",
      "32/32 - 0s - loss: 0.3963 - 10ms/epoch - 306us/step\n",
      "Epoch 28/100\n",
      "32/32 - 0s - loss: 0.3857 - 9ms/epoch - 291us/step\n",
      "Epoch 29/100\n",
      "32/32 - 0s - loss: 0.3745 - 10ms/epoch - 310us/step\n",
      "Epoch 30/100\n",
      "32/32 - 0s - loss: 0.4167 - 10ms/epoch - 312us/step\n",
      "Epoch 31/100\n",
      "32/32 - 0s - loss: 0.4165 - 9ms/epoch - 293us/step\n",
      "Epoch 32/100\n",
      "32/32 - 0s - loss: 0.3878 - 10ms/epoch - 313us/step\n",
      "Epoch 33/100\n",
      "32/32 - 0s - loss: 0.3745 - 9ms/epoch - 291us/step\n",
      "Epoch 34/100\n",
      "32/32 - 0s - loss: 0.3861 - 10ms/epoch - 306us/step\n",
      "Epoch 35/100\n",
      "32/32 - 0s - loss: 0.4058 - 10ms/epoch - 305us/step\n",
      "Epoch 36/100\n",
      "32/32 - 0s - loss: 0.3673 - 9ms/epoch - 292us/step\n",
      "Epoch 37/100\n",
      "32/32 - 0s - loss: 0.4202 - 10ms/epoch - 301us/step\n",
      "Epoch 38/100\n",
      "32/32 - 0s - loss: 0.3836 - 10ms/epoch - 308us/step\n",
      "Epoch 39/100\n",
      "32/32 - 0s - loss: 0.4034 - 10ms/epoch - 299us/step\n",
      "Epoch 40/100\n",
      "32/32 - 0s - loss: 0.3813 - 10ms/epoch - 308us/step\n",
      "Epoch 41/100\n",
      "32/32 - 0s - loss: 0.3748 - 9ms/epoch - 296us/step\n",
      "Epoch 42/100\n",
      "32/32 - 0s - loss: 0.3826 - 10ms/epoch - 304us/step\n",
      "Epoch 43/100\n",
      "32/32 - 0s - loss: 0.3898 - 9ms/epoch - 291us/step\n",
      "Epoch 44/100\n",
      "32/32 - 0s - loss: 0.3886 - 9ms/epoch - 294us/step\n",
      "Epoch 45/100\n",
      "32/32 - 0s - loss: 0.3661 - 10ms/epoch - 302us/step\n",
      "Epoch 46/100\n",
      "32/32 - 0s - loss: 0.3832 - 9ms/epoch - 295us/step\n",
      "Epoch 47/100\n",
      "32/32 - 0s - loss: 0.3949 - 10ms/epoch - 309us/step\n",
      "Epoch 48/100\n",
      "32/32 - 0s - loss: 0.3972 - 10ms/epoch - 308us/step\n",
      "Epoch 49/100\n",
      "32/32 - 0s - loss: 0.3785 - 9ms/epoch - 286us/step\n",
      "Epoch 50/100\n",
      "32/32 - 0s - loss: 0.4053 - 10ms/epoch - 307us/step\n",
      "Epoch 51/100\n",
      "32/32 - 0s - loss: 0.4326 - 10ms/epoch - 301us/step\n",
      "Epoch 52/100\n",
      "32/32 - 0s - loss: 0.3556 - 9ms/epoch - 292us/step\n",
      "Epoch 53/100\n",
      "32/32 - 0s - loss: 0.3992 - 10ms/epoch - 304us/step\n",
      "Epoch 54/100\n",
      "32/32 - 0s - loss: 0.4294 - 9ms/epoch - 291us/step\n",
      "Epoch 55/100\n",
      "32/32 - 0s - loss: 0.3947 - 10ms/epoch - 308us/step\n",
      "Epoch 56/100\n",
      "32/32 - 0s - loss: 0.4328 - 10ms/epoch - 297us/step\n",
      "Epoch 57/100\n",
      "32/32 - 0s - loss: 0.3702 - 10ms/epoch - 301us/step\n",
      "Epoch 58/100\n",
      "32/32 - 0s - loss: 0.4091 - 10ms/epoch - 308us/step\n",
      "Epoch 59/100\n",
      "32/32 - 0s - loss: 0.3888 - 9ms/epoch - 287us/step\n",
      "Epoch 60/100\n",
      "32/32 - 0s - loss: 0.4776 - 10ms/epoch - 305us/step\n",
      "Epoch 61/100\n",
      "32/32 - 0s - loss: 0.3709 - 11ms/epoch - 331us/step\n",
      "Epoch 62/100\n",
      "32/32 - 0s - loss: 0.3780 - 11ms/epoch - 351us/step\n",
      "Epoch 63/100\n",
      "32/32 - 0s - loss: 0.3882 - 10ms/epoch - 318us/step\n",
      "Epoch 64/100\n",
      "32/32 - 0s - loss: 0.3938 - 10ms/epoch - 308us/step\n",
      "Epoch 65/100\n",
      "32/32 - 0s - loss: 0.4240 - 9ms/epoch - 294us/step\n",
      "Epoch 66/100\n",
      "32/32 - 0s - loss: 0.3928 - 10ms/epoch - 308us/step\n",
      "Epoch 67/100\n",
      "32/32 - 0s - loss: 0.4294 - 9ms/epoch - 296us/step\n",
      "Epoch 68/100\n",
      "32/32 - 0s - loss: 0.3993 - 10ms/epoch - 307us/step\n",
      "Epoch 69/100\n",
      "32/32 - 0s - loss: 0.3970 - 10ms/epoch - 308us/step\n",
      "Epoch 70/100\n",
      "32/32 - 0s - loss: 0.3842 - 9ms/epoch - 296us/step\n",
      "Epoch 71/100\n",
      "32/32 - 0s - loss: 0.3702 - 10ms/epoch - 305us/step\n",
      "Epoch 72/100\n",
      "32/32 - 0s - loss: 0.3722 - 11ms/epoch - 340us/step\n",
      "Epoch 73/100\n",
      "32/32 - 0s - loss: 0.3842 - 9ms/epoch - 296us/step\n",
      "Epoch 74/100\n",
      "32/32 - 0s - loss: 0.3884 - 10ms/epoch - 305us/step\n",
      "Epoch 75/100\n",
      "32/32 - 0s - loss: 0.3862 - 10ms/epoch - 298us/step\n",
      "Epoch 76/100\n",
      "32/32 - 0s - loss: 0.3934 - 10ms/epoch - 308us/step\n",
      "Epoch 77/100\n",
      "32/32 - 0s - loss: 0.4331 - 10ms/epoch - 303us/step\n",
      "Epoch 78/100\n",
      "32/32 - 0s - loss: 0.3911 - 9ms/epoch - 292us/step\n",
      "Epoch 79/100\n",
      "32/32 - 0s - loss: 0.4134 - 10ms/epoch - 311us/step\n",
      "Epoch 80/100\n",
      "32/32 - 0s - loss: 0.4134 - 9ms/epoch - 295us/step\n",
      "Epoch 81/100\n",
      "32/32 - 0s - loss: 0.4034 - 10ms/epoch - 303us/step\n",
      "Epoch 82/100\n",
      "32/32 - 0s - loss: 0.3885 - 10ms/epoch - 306us/step\n",
      "Epoch 83/100\n",
      "32/32 - 0s - loss: 0.3814 - 9ms/epoch - 292us/step\n",
      "Epoch 84/100\n",
      "32/32 - 0s - loss: 0.3931 - 10ms/epoch - 311us/step\n",
      "Epoch 85/100\n",
      "32/32 - 0s - loss: 0.3732 - 10ms/epoch - 300us/step\n",
      "Epoch 86/100\n",
      "32/32 - 0s - loss: 0.4127 - 9ms/epoch - 292us/step\n",
      "Epoch 87/100\n",
      "32/32 - 0s - loss: 0.3852 - 10ms/epoch - 309us/step\n",
      "Epoch 88/100\n",
      "32/32 - 0s - loss: 0.3874 - 9ms/epoch - 295us/step\n",
      "Epoch 89/100\n",
      "32/32 - 0s - loss: 0.3930 - 10ms/epoch - 306us/step\n",
      "Epoch 90/100\n",
      "32/32 - 0s - loss: 0.4023 - 10ms/epoch - 322us/step\n",
      "Epoch 91/100\n",
      "32/32 - 0s - loss: 0.4091 - 9ms/epoch - 294us/step\n",
      "Epoch 92/100\n",
      "32/32 - 0s - loss: 0.4197 - 10ms/epoch - 310us/step\n",
      "Epoch 93/100\n",
      "32/32 - 0s - loss: 0.3657 - 9ms/epoch - 295us/step\n",
      "Epoch 94/100\n",
      "32/32 - 0s - loss: 0.3993 - 10ms/epoch - 308us/step\n",
      "Epoch 95/100\n",
      "32/32 - 0s - loss: 0.3832 - 13ms/epoch - 417us/step\n",
      "Epoch 96/100\n",
      "32/32 - 0s - loss: 0.4445 - 11ms/epoch - 339us/step\n",
      "Epoch 97/100\n",
      "32/32 - 0s - loss: 0.3922 - 12ms/epoch - 365us/step\n",
      "Epoch 98/100\n",
      "32/32 - 0s - loss: 0.3827 - 10ms/epoch - 298us/step\n",
      "Epoch 99/100\n",
      "32/32 - 0s - loss: 0.3886 - 10ms/epoch - 312us/step\n",
      "Epoch 100/100\n",
      "32/32 - 0s - loss: 0.3832 - 9ms/epoch - 290us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc5815be50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(datos['entradas'], datos['targets'], epochs = 100, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extracción de los pesos y sesgos\n",
    "\n",
    "La extracción de el(los) peso(s) y sesgo(s) de un modelo no es un paso esencial para el proceso de ML.  De hecho, en un contexto de aprendizaje profundo, no da mucha información útil.  Sin embargo, este ejemplo simple se armó de tal forma que permite verificar si las respuestas que da el modelo son correctas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.layers[0].get_weights()    # el cero (0) es porque solo tenemos una capa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden almacenar los pesos y los sesgos en variables diferentes para facilitar la revisión.\n",
    "\n",
    "OJO!   Pueden haber cientos o miles de estos!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pesos = modelo.layers[0].get_weights()[0]\n",
    "pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sesgos = modelo.layers[0].get_weights()[1]\n",
    "sesgos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacer predicciones\n",
    "\n",
    "Una vez más, este no es un paso esencial, sin embargo, generalmente sí se desean hacer predicciones.\n",
    "\n",
    "Se puede pedirle al modelo que prediga nuevos valores.  A veces es útil redondear los valores para que la salida sea más legible.  \n",
    "\n",
    "Generalmente se utiliza este método con DATOS NUEVOS, en vez de usar los datos de entrenamiento originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.predict_on_batch(datos['entradas']).round(1)[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se despliegan la metas (valores reales), se pueden comparar visualmente con las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos['targets'].round(1)[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficar los datos\n",
    "\n",
    "El modelo está ya optimizado, por lo que las salidas se han calculado sobre la última forma, o el último estado, del modelo.\n",
    "\n",
    "Es necesario comprimir o empacar **\"squeeze\"** los arreglos para dejarlos en un formato que es el esperado por la función graficadora.  No cambia nada ya que se dejaron dimensiones de tamaño 1 - solo es un tecnisismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.squeeze(modelo.predict_on_batch(datos['entradas'])), \n",
    "         np.squeeze(datos['targets']))\n",
    "plt.xlabel('predicciones')\n",
    "plt.ylabel('metas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con Plotly Express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x = np.squeeze(modelo.predict_on_batch(datos['entradas'])), \n",
    "                 y =  np.squeeze(datos['targets']))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Comparación predicciones vrs metas\",\n",
    "    xaxis_title=\"Predicciones\",\n",
    "    yaxis_title=\"Metas\",\n",
    "    width = 600,\n",
    "    height = 400,)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listo, lo que se vé debe ser exactamente igual a lo que se vió en el ejercicio pasado!\n",
    "\n",
    "A estas alturas quizás no se le ve la gracia al TensorFlow.  En términos de líneas código es igual al del ejercicio con NumPy para llegar al mismo resultado.  Sin embargo, a medida que se profundice en el tema, se podrá ver que TensorFlow ahorra cientos de líneas de código."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
